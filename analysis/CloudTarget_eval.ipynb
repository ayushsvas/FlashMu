{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from patchify import patchify, unpatchify\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "from csfm.dfc import dfc as f_c_network\n",
    "from det_head.CNOModule import CNO\n",
    "# from det_head.upernetconvnext import uperconvnext\n",
    "# import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "\n",
    "from config_dfc_unet_eval import config\n",
    "from plotting_tools import *\n",
    "import gc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tex_fonts = {\n",
    "    # Use LaTeX to write all text\n",
    "    \"text.usetex\": False,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    # \"font.sans-serif\": \"Helvetica\",\n",
    "    # Use 10pt font in plots, to match 10pt font in document\n",
    "    \"axes.labelsize\": 9,\n",
    "    \"font.size\": 9,\n",
    "    # Make the legend/label fonts a little smaller\n",
    "    \"legend.fontsize\": 8,\n",
    "    \"xtick.labelsize\": 8,\n",
    "    \"ytick.labelsize\": 8\n",
    "}\n",
    "\n",
    "plt.rcParams.update(tex_fonts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utils, will use these from the utils python files later\n",
    "def load_checkpoint(checkpoint, dfc, optimizer: None):\n",
    "    print(\"==> Loading checkpoint\")\n",
    "    dfc.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "        for param_group in optimizer.param_groups:\n",
    "            lr = param_group[\"lr\"]\n",
    "        print(\"Loading Optimizer. Current learning rate = \", lr)\n",
    "\n",
    "def count_params(model) -> float:\n",
    "        \"\"\"Calculate model parameters memory usage in MB.\"\"\"\n",
    "        model_size = 0\n",
    "        for param in model.parameters():\n",
    "            model_size += param.nelement() * param.element_size()\n",
    "        return model_size / (1024 ** 3)  # Convert bytes to MB\n",
    "        \n",
    "def gkern(l=5, sig=1.):\n",
    "    \"\"\"\\\n",
    "    creates gaussian kernel with side length `l` and a sigma of `sig`\n",
    "    \"\"\"\n",
    "    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)\n",
    "    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))\n",
    "    kernel = np.outer(gauss, gauss)\n",
    "    return kernel\n",
    "\n",
    "def mask_maker(X, Y, Z, R, N_x = 512, N_y = 512, kernel_size = 5):\n",
    "    dx = 3e-6 # for 5120\n",
    "    dz = 1e-3\n",
    "    dr = 1e-6\n",
    "    \n",
    "    X = np.round(np.array(X)).astype(int)\n",
    "    Y = np.round(np.array(Y)).astype(int)\n",
    "    \n",
    "    Z = (np.array(Z))\n",
    "    R = (np.array(R))\n",
    "    \n",
    "    gk = gkern(l = kernel_size, sig = 1)\n",
    "    mask  = np.zeros((3, N_y + kernel_size + 2, N_x + kernel_size + 2))\n",
    "    \n",
    "    for (x,y,z,r) in zip(X,Y,Z,R):\n",
    "\n",
    "\n",
    "        mask[0,(kernel_size//2+y-kernel_size//2):(kernel_size//2+y+kernel_size//2+1),(kernel_size//2+x-kernel_size//2):(kernel_size//2+x+kernel_size//2+1)] = gk # Use this for synthetic \n",
    "        mask[1,(kernel_size//2+y-kernel_size//2):(kernel_size//2+y+kernel_size//2+1),(kernel_size//2+x-kernel_size//2):(kernel_size//2+x+kernel_size//2+1)] = z\n",
    "        mask[2,(kernel_size//2+y-kernel_size//2):(kernel_size//2+y+kernel_size//2+1),(kernel_size//2+x-kernel_size//2):(kernel_size//2+x+kernel_size//2+1)] = r\n",
    "\n",
    "\n",
    "    return mask[:,1+kernel_size//2:N_y+1+kernel_size//2,1+kernel_size//2:N_x+1+kernel_size//2]\n",
    "\n",
    "def peak_local_max(input, threshold_abs=1, min_distance=1):\n",
    "    '''\n",
    "    Returns a binary map where maxima positions are true.\n",
    "\n",
    "        Parameters:\n",
    "            input (pytorch tensor): image-like pytorch tensor of dimension [batch_size, channels, width, height], where each image will be processed individually\n",
    "            threshold_abs (float): local maxima below will be dropped\n",
    "            min_distance (int): min distance (in pixels) between two maxima detections.\n",
    "        Returns\n",
    "            pytorch tensor of same shape as input\n",
    "    '''\n",
    "    max_filtered=nn.functional.max_pool2d(input, kernel_size=2*min_distance+1, stride=1, padding=min_distance)\n",
    "    maxima = torch.eq(max_filtered, input)\n",
    "    return maxima * (input >= threshold_abs)\n",
    "\n",
    "epsilon = 2.2204e-16\n",
    "def precision(hits, fp):\n",
    "    if hits == 0 and fp == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return hits/(hits+fp+epsilon)\n",
    "\n",
    "def recall(hits, fn):\n",
    "    if hits == 0 and fn == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    else:\n",
    "        return hits/(hits+fn+epsilon)\n",
    "\n",
    "def f1(precision, recall):\n",
    "    return 2*(precision*recall)/(precision+recall+epsilon)\n",
    "\n",
    "\n",
    "def get_grid(shape, device):\n",
    "        batchsize, size_x, size_y = shape[0], shape[2], shape[3]\n",
    "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "        # print(gridx.shape)\n",
    "        gridx = gridx.reshape(1, 1, size_x, 1).repeat([batchsize, 1, 1, size_y])\n",
    "        # print(gridx.shape)\n",
    "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, 1, size_y).repeat([batchsize, 1, size_x, 1])\n",
    "        return torch.cat((gridx, gridy), dim=1).to(device)\n",
    "\n",
    "def make_smaller_patches(input: torch.tensor, patch_size: int = 128, step: int = 128, device: str = 'cuda'):\n",
    "    input = input.cpu().detach().numpy()[0,0]\n",
    "    input = patchify(input, patch_size=patch_size, step=step)\n",
    "    intermediate_shape = input.shape\n",
    "    input = np.reshape(input, (input.shape[0]*input.shape[1],patch_size, patch_size))\n",
    "    input = torch.from_numpy(input).unsqueeze(1).to(device)\n",
    "    return input, intermediate_shape\n",
    "\n",
    "def patch_batch(input: torch.tensor, im_shape: tuple = (256,256), intermediate_shape:tuple = (2,2,256,256), device: str = 'cuda'):\n",
    "    input = input.cpu().detach().numpy()\n",
    "    input = np.reshape(input, intermediate_shape)\n",
    "    input = unpatchify(input, imsize = im_shape)\n",
    "    input = torch.from_numpy(input).unsqueeze(0)\n",
    "    return input \n",
    "\n",
    "\n",
    "def make_img_crops(img_files, crops_per_hologram, crop_size, step_size, W, edge_crop_dist, ds_factor):\n",
    "    num_files = len(img_files)\n",
    "    inp = np.zeros((crops_per_hologram*num_files,crop_size,crop_size)) # storing them in a numpy array \n",
    "    i = 0\n",
    "    xy_slices = (slice(edge_crop_dist, W-edge_crop_dist), slice(edge_crop_dist, W-edge_crop_dist)) \n",
    "\n",
    "    # print(\"Now downsampling and cropping...\")\n",
    "    avgpool = nn.AvgPool2d(ds_factor,ds_factor)\n",
    "\n",
    "    for f in img_files:\n",
    "        holo = avgpool(torch.from_numpy(np.float32(np.array(Image.open(f)))).unsqueeze(0)).squeeze(0).numpy()[xy_slices]\n",
    "        # print(\"Downsampled hologram shape\", holo.shape)\n",
    "        holo_patches = patchify(holo, patch_size=crop_size, step=step_size)\n",
    "\n",
    "        holo_patches = np.reshape(holo_patches, (holo_patches.shape[0]*holo_patches.shape[1], crop_size, crop_size))\n",
    "        inp[i:i+holo_patches.shape[0]] = holo_patches\n",
    "        # print(\"Crops obtained\", holo_patches.shape) \n",
    "        i += holo_patches.shape[0]\n",
    "\n",
    "    inp = torch.from_numpy(inp).unsqueeze(1).float() # converting to torch and float32\n",
    "    # for i in range(inp.shape[0]):\n",
    "    #     inp[i] = torch.clip((inp[i]-torch.mean(inp[i]))*2, 0, 255)\n",
    "    # print(\"Final test data shape\", inp.shape)\n",
    "    return inp\n",
    "\n",
    "\n",
    "def make_msk_crops(m_files, crops_per_hologram, crop_size, step_size, W, edge_crop_dist, ds_factor, gkern_size, dist_from_crop_corner):\n",
    "    # Borrowing from above \n",
    "    num_files = len(m_files)\n",
    "\n",
    "    # Desired shape of the target labels, adjust accordingly \n",
    "    target = torch.zeros((num_files*crops_per_hologram,3,crop_size,crop_size))\n",
    "\n",
    "    # some known paramters of the ground truth\n",
    "    dr = 3 #um, pixel size\n",
    "    Z = [50.0, 99.0, 167.0, 192.0, 75.0] # z values of the ground truth \n",
    "    # domain of ground truth\n",
    "    xmin = 0\n",
    "    ymin = 0\n",
    "    xmax = 5120\n",
    "    ymax = 5120\n",
    "\n",
    "\n",
    "    # adjust this for matching. At downsampled levek kernel_size = 7 would men 3*4*3 x 3*4*3 Âµm2 area around the ground truth center will be checked for matching. \n",
    "    kernel_size = gkern_size\n",
    "\n",
    "    i = 0\n",
    "    for file_num in range(len(m_files)):\n",
    "\n",
    "        data = np.genfromtxt(m_files[file_num])\n",
    "        x = data[:,0]\n",
    "        y = data[:,1]\n",
    "        d = data[:,2]*dr\n",
    "        z = np.ones(x.shape[0])*Z[file_num]\n",
    "\n",
    "\n",
    "        # throw away values if there are any out of the 5120 domain \n",
    "        xx = x[(x>xmin)*(y>ymin)*(x<xmax)*(y<ymax)]\n",
    "        yy = y[(x>xmin)*(y>ymin)*(x<xmax)*(y<ymax)]\n",
    "        zz = z[(x>xmin)*(y>ymin)*(x<xmax)*(y<ymax)]\n",
    "        dd = d[(x>xmin)*(y>ymin)*(x<xmax)*(y<ymax)]\n",
    "\n",
    "        \n",
    "        xy_slices = (slice(3), slice(edge_crop_dist, W-edge_crop_dist), slice(edge_crop_dist,W-edge_crop_dist))\n",
    "        # converts sparse coordinates into images for matching and slices out the the earlier cropped edges\n",
    "        tgt = mask_maker(xx/ds_factor, yy/ds_factor, zz, dd, xmax//ds_factor, ymax//ds_factor, kernel_size = kernel_size)[xy_slices]\n",
    "        # print(f\"For hologram {W}x{W} at Z = {Z[file_num]}mm, ground truth mask of shape {tgt.shape} is made.\")\n",
    "        \n",
    "        # Below we crop the big masks\n",
    "        mask_4ds = tgt\n",
    "        xy_masks = patchify(np.flipud(mask_4ds[0]), crop_size, step_size)\n",
    "        z_masks = patchify(np.flipud(mask_4ds[1]), crop_size, step_size)\n",
    "        r_masks = patchify(np.flipud(mask_4ds[2]), crop_size, step_size)\n",
    "\n",
    "        xy_masks = xy_masks.reshape((xy_masks.shape[0]*xy_masks.shape[1], crop_size, crop_size))\n",
    "        z_masks = z_masks.reshape((z_masks.shape[0]*z_masks.shape[1], crop_size, crop_size))\n",
    "        r_masks = r_masks.reshape((r_masks.shape[0]*r_masks.shape[1], crop_size, crop_size))\n",
    "        masks_4ds = np.concatenate((xy_masks[:,np.newaxis,:,:],z_masks[:,np.newaxis,:,:],r_masks[:,np.newaxis,:,:]), axis = 1)\n",
    "        tgt = masks_4ds\n",
    "\n",
    "        tgt = torch.from_numpy(tgt)\n",
    "        # print(f\"Cropped the mask into {list(tgt.shape)}!\")\n",
    "        target[i:i+tgt.shape[0]] = tgt\n",
    "        i += tgt.shape[0]\n",
    "        \n",
    "    tgt = target\n",
    "    # print(\"Final test target mask shape\", tgt.shape)\n",
    "    dist_from_corner = dist_from_crop_corner #128, 64\n",
    "    slice_holo = (slice(None), slice(None), slice(dist_from_corner, crop_size-dist_from_corner), slice(dist_from_corner, crop_size-dist_from_corner))\n",
    "    return tgt[slice_holo]\n",
    "\n",
    "def error_analysis(tgt, store_xy2, store_z2, store_r2, best_cutoff, min_distance, kernel_size, file_indices, min_r, max_r, ez_allowed):\n",
    "    # note the best_cutoff and min_distance from above \n",
    "    threshold = best_cutoff\n",
    "    min_distance = min_distance\n",
    "\n",
    "    # storing the predicted z and size values for error analysis \n",
    "    z_predictions = []\n",
    "    r_predictions = []\n",
    "    z_detected = []\n",
    "    r_detected = []\n",
    "    \n",
    "    # similar stuff as above, extratcing locations and sizes at best_cutoff from intersections and storing them for error calculation later\n",
    "    for i in range(len(store_xy2[file_indices])):\n",
    "        true_mask = ((tgt[i,0] > gkern(kernel_size).min()).float()).unsqueeze(0)\n",
    "        peak_finding_mask = peak_local_max((store_xy2[i]*true_mask), threshold_abs=threshold, min_distance=kernel_size//2+1)\n",
    "        \n",
    "        z_values_predicted = store_z2[i][peak_finding_mask]\n",
    "        z_predictions.append(z_values_predicted)\n",
    "        z_values_detected = (tgt[i,1]).unsqueeze(0)[peak_finding_mask]\n",
    "        z_detected.append(z_values_detected)\n",
    "\n",
    "        r_values_predicted = store_r2[i][peak_finding_mask]\n",
    "        r_predictions.append(r_values_predicted)\n",
    "        r_values_detected = (tgt[i,2]).unsqueeze(0)[peak_finding_mask]\n",
    "        r_detected.append(r_values_detected)\n",
    "\n",
    "\n",
    "\n",
    "    # this extracts the z and size values from ground truth\n",
    "    z_true = []\n",
    "    r_true = []\n",
    "    for i in range(len(store_xy2[file_indices])):\n",
    "        peak_finding_mask = peak_local_max(tgt[i,0].unsqueeze(0), threshold_abs=0.6, min_distance=1).squeeze(0)\n",
    "        z_values_true = tgt[i,1][peak_finding_mask]\n",
    "        z_true.append(z_values_true)\n",
    "        r_values_true = tgt[i,2][peak_finding_mask]\n",
    "        r_true.append(r_values_true)\n",
    "\n",
    "    d_total  = []\n",
    "    z_total = []\n",
    "    for r,z in zip(r_true, z_true):\n",
    "        for rr, zz in zip(r, z):\n",
    "            if rr > max_r or rr < min_r:\n",
    "                continue\n",
    "            d_total.append(rr)\n",
    "            z_total.append(zz)\n",
    "    z_total = np.array(z_total)\n",
    "    d_total = np.array(d_total)\n",
    "\n",
    "    # above the data structure is crop wise. Here we make them independent of crop. Storing error values per detected/matched particle.\n",
    "    Z_true = []\n",
    "    Z_pred = []\n",
    "    R_true = []\n",
    "    R_pred = []\n",
    "    ez_det = []\n",
    "    er_det = [] \n",
    "    \n",
    "\n",
    "    for zpred, rpred, ztrue, rtrue  in zip(z_predictions, r_predictions, z_detected, r_detected):\n",
    "\n",
    "        for zt, zp, rt, rp, ez, er in zip(ztrue, zpred ,rtrue, rpred, np.abs(zpred-ztrue), np.abs(rpred-rtrue)):\n",
    "        \n",
    "        # we don't calculate error for particles out of size range and ez_allowed \n",
    "            if rt > max_r or rt < min_r or ez > ez_allowed:\n",
    "                \n",
    "                continue\n",
    "\n",
    "            Z_true.append(zt.cpu())\n",
    "            Z_pred.append(zp.cpu())\n",
    "            R_true.append(rt.cpu())\n",
    "            R_pred.append(rp.cpu())\n",
    "            ez_det.append(ez.cpu())\n",
    "            er_det.append(er.cpu())\n",
    "            \n",
    "    # convert to numpy for convenience\n",
    "    z_det = torch.asarray(Z_true).numpy()\n",
    "    d_det = torch.asarray(R_true).numpy()\n",
    "    d_pred = torch.asarray(R_pred).numpy()\n",
    "    z_pred = torch.asarray(Z_pred).numpy()\n",
    "    ez_det = torch.asarray(ez_det).numpy()\n",
    "    ed_det = torch.asarray(er_det).numpy()\n",
    "    \n",
    "    return ez_det, ed_det, z_det, z_pred, d_det, d_pred, d_total, z_total\n",
    "    \n",
    "\n",
    "def _eval_prec_rec_f1_(tgt, store_xy2, store_z2, store_r2, gkern_size, num_files, num_crops_per_holo, \n",
    "                       cutoff_range, min_distance, max_r, min_r, max_z, min_z, ez_allowed, error_calc):\n",
    "    kernel_size = gkern_size\n",
    "    \n",
    "\n",
    "    # dictionaries for storing per cutoff value the below\n",
    "    false_postives = {} \n",
    "    false_negatives = {}\n",
    "    interesections = {}\n",
    "\n",
    "    hit_box_size_param = gkern(l = kernel_size, sig = 1).min() #predictions are checked within the hitbox \n",
    "     \n",
    "    num_ez_outlier = 0 # counts false positives due to ez<ez_allowed criteria \n",
    "\n",
    "    # middle_crop = (slice(None), slice(None), slice(), slice())\n",
    "\n",
    "    gt_particles = peak_local_max(tgt[:,0].unsqueeze(1), 0.8, 2) # converting gauss maps to binary mask, considering only peaks \n",
    "\n",
    "    # dictionaries for storing per cutoff value the below\n",
    "    pr = {} # precision \n",
    "    rc = {} # recall\n",
    "    f1s = {} # f1 score \n",
    "\n",
    "    # if want to evaluate all five holograms\n",
    "    num_samples = num_files*num_crops_per_holo  \n",
    "    file_index = 0 \n",
    "\n",
    "    # num_samples = 1*num_crops_per_holo # if want to evaluate one hologram \n",
    "    # file_index = 0 # 0,1,2,3,4 corresponds to z = 50mm, 99mm, 167mm, 192mm, 75mm \n",
    "\n",
    "    # DO NOT CHANGE\n",
    "    start_file_index = 0 + file_index*9 \n",
    "    file_indices = slice(start_file_index,start_file_index+num_samples)\n",
    "    i = start_file_index\n",
    "\n",
    "    for cutoff in trange(1,cutoff_range+1):\n",
    "\n",
    "        threshold = cutoff/cutoff_range # brings the cutoff between 0 and 1\n",
    "\n",
    "        # initialize keys \n",
    "        if threshold not in false_negatives:\n",
    "            false_postives[threshold] = 0  \n",
    "            false_negatives[threshold] = 0\n",
    "            interesections[threshold] = 0\n",
    "            rc[threshold] = 0\n",
    "            pr[threshold] = 0\n",
    "            f1s[threshold] = 0\n",
    "\n",
    "        # for tracking precision, recall and f1 per crop\n",
    "        tmp_pr = 0\n",
    "        tmp_rc = 0\n",
    "        tmp_f1 = 0\n",
    "\n",
    "        for j, sample in enumerate(store_xy2[file_indices]):\n",
    "            \n",
    "            # extract precited particle locations, notice store_xy map above. \n",
    "            predicted_particles = peak_local_max(sample, threshold_abs=threshold, min_distance=min_distance) \n",
    "            # find intersections\n",
    "            hits = peak_local_max((sample*predicted_particles)*((tgt[i,0]>=hit_box_size_param).float()).unsqueeze(0), threshold_abs=threshold, min_distance=kernel_size//2)\n",
    "            # check for outliers with respect to ground truth. Remove particles below min_r and above max_r\n",
    "            gt_sizes_out_of_domain = tgt[i,2][gt_particles[i,0]]\n",
    "            gt_sizes_out_of_domain = ((gt_sizes_out_of_domain > max_r) + (gt_sizes_out_of_domain < min_r)).sum()\n",
    "            # check for outliers with respect to interesections. Remove particles below min_r and above max_r\n",
    "            hits_sizes_out_of_domain = tgt[i,2][hits.squeeze(0)]\n",
    "            hits_sizes_out_of_domain = ((hits_sizes_out_of_domain > max_r) + (hits_sizes_out_of_domain < min_r)).sum()\n",
    "            # detected z_values at intersections\n",
    "            gt_z_detected = tgt[i,1][hits.squeeze(0)]\n",
    "            # predicted z_values at intersections \n",
    "            pred_z_detected = store_z2[i][hits]\n",
    "            # count the particles which match in xy but are terribly predicted in z\n",
    "            num_ez_outlier = (torch.abs(pred_z_detected-gt_z_detected) > ez_allowed).sum()\n",
    "\n",
    "            # binary masks to scalars, removing out-of-domain particles and false postives with respect to z from intersections\n",
    "            hits = hits.sum()-hits_sizes_out_of_domain-num_ez_outlier\n",
    "            # same for false positives\n",
    "            fp = (predicted_particles.sum()-hits_sizes_out_of_domain) - (hits)\n",
    "            # same for false negatives\n",
    "            fn =(gt_particles[i,0].sum()-gt_sizes_out_of_domain) - (hits+num_ez_outlier) # add num_ez_outlier here because they are false positves and added there.\n",
    "            # checks for overcounting, number of matched particles shouldn't be greater than the ground truth. \n",
    "            \n",
    "    \n",
    "            if hits>hits+fn:\n",
    "                # print((gt_particles[i,0].sum()-gt_sizes_out_of_domain), hits)\n",
    "                # print(f\"Overcounting by {hits-hits-fn}\")\n",
    "                fn = 0\n",
    "                fp += hits - (hits+fn)\n",
    "                hits -= hits - (hits+fn)\n",
    "\n",
    "\n",
    "            # accumulate for calculating precision, recall and f1 score for all five holograms together. \n",
    "            false_postives[threshold] += fp\n",
    "            false_negatives[threshold] += fn\n",
    "            interesections[threshold] += hits\n",
    "\n",
    "            #this calculates the same but per crop and later we average\n",
    "            tmp_pr += precision(hits, fp)\n",
    "            tmp_rc += recall(hits, fn)\n",
    "            tmp_f1 += f1(tmp_pr, tmp_rc)\n",
    "        \n",
    "            i += 1\n",
    "        i = start_file_index\n",
    "        \n",
    "        # precision, recall and f1 per crop per cutoff\n",
    "        pr[threshold] = tmp_pr/num_samples\n",
    "        rc[threshold] = tmp_rc/num_samples\n",
    "        f1s[threshold] = tmp_f1/num_samples\n",
    "\n",
    "\n",
    "    # code below calculates the precision, recall and f1 for all five holograms together \n",
    "    P = []\n",
    "    R = []\n",
    "    f1_score = []\n",
    "\n",
    "    # best points in terms of f1 score \n",
    "    best_cutoff = 0 # cutoff at best f1\n",
    "    best_cutoff_index = 0\n",
    "    best_f1 = 0\n",
    "    R_star = 0 # Recall at best f1\n",
    "    P_star = 0 # Precision at best f1\n",
    "\n",
    "    for index, cutoff in enumerate(interesections):\n",
    "        # if for very high cutoff (0.99), you're still getting false positives (by accident), have to remove them this way to \n",
    "        # make the precision-recall curve not look weird.\n",
    "        if cutoff > 0.99:\n",
    "            if false_negatives[cutoff] > 0:\n",
    "                false_postives[cutoff] = 0\n",
    "\n",
    "        prec = precision(interesections[cutoff], false_postives[cutoff])\n",
    "        rec = recall(interesections[cutoff], false_negatives[cutoff])\n",
    "        if prec == 0 and rec == 0:\n",
    "            print(f\"{prec} precision and {rec} recall at {cutoff}. Either manually remove such cases, or find the bug!\")    \n",
    "        F1 = f1(prec, rec)\n",
    "        \n",
    "        # block for tracking the best f1\n",
    "        if F1 > best_f1:\n",
    "            best_f1 = F1\n",
    "            best_cutoff = cutoff \n",
    "            best_cutoff_index = index\n",
    "            R_star = rec\n",
    "            P_star = prec\n",
    "\n",
    "        P.append(float(prec))\n",
    "        R.append(float(rec))\n",
    "        f1_score.append(float(F1))\n",
    "\n",
    "    # print('(Cutoff of at max F1, Precision at max F1, Recall at max F1, Max. F1):', best_cutoff, float(P_star), \n",
    "    #       float(R_star), float(best_f1))\n",
    "        \n",
    "    if error_calc:\n",
    "        _, _, z_det, z_pred, d_det, d_pred, d_total, z_total = error_analysis(tgt, store_xy2, store_z2, store_r2, best_cutoff, min_distance, kernel_size, file_indices, min_r, max_r, ez_allowed)\n",
    "        print(\"Putting everyhting into a dictionary...\")\n",
    "        prediction_dict = {\n",
    "            \"precision\": P,\n",
    "            \"recall\": R,\n",
    "            \"F1\": f1_score,\n",
    "            \"best_F1\":  float(best_f1),\n",
    "            \"precision_at_best_f1\": float(P_star),\n",
    "            \"recall_at_best_f1\": float(R_star),\n",
    "            \"z_detected\": z_det,\n",
    "            \"z_predicted\": z_pred,\n",
    "            \"d_detected\": d_det,\n",
    "            \"d_predicted\": d_pred,\n",
    "            \"z_all_in_gt\": z_total,\n",
    "            \"d_all_in_gt\":d_total\n",
    "        }\n",
    "\n",
    "        # return P, R, f1_score,  float(P_star), float(R_star), float(best_f1), ez, ed, z_det, z_pred, d_det, d_pred, d_total, z_total\n",
    "        return prediction_dict\n",
    "    \n",
    "    return P, R, f1_score, float(P_star), float(R_star), float(best_f1)\n",
    "\n",
    "\n",
    "def _get_dfcs(config):\n",
    "    device = config[\"test\"][\"device\"] \n",
    "\n",
    "    dfc, unet = None, None\n",
    "\n",
    "    if config[\"test\"][\"dfc\"]:\n",
    "\n",
    "\n",
    "        in_channels = config[\"dfc\"][\"fourier_part\"][\"in_channels\"]\n",
    "        hidden_channels = config[\"dfc\"][\"fourier_part\"][\"hidden_channels\"]\n",
    "        n_modes = config[\"dfc\"][\"fourier_part\"][\"n_modes\"]\n",
    "        fourier_interpolation = config[\"dfc\"][\"fourier_part\"][\"fourier_interpolation\"]\n",
    "        bias = config[\"dfc\"][\"fourier_part\"][\"bias\"]\n",
    "        skip = config[\"dfc\"][\"fourier_part\"][\"skip\"]\n",
    "        dilate_fourier_kernel_fac = config[\"dfc\"][\"fourier_part\"][\"dilate_fourier_kernel_fac\"]\n",
    "        lifting_channels = config[\"dfc\"][\"fourier_part\"][\"lifting_channels\"]\n",
    "        projection_channels = config[\"dfc\"][\"fourier_part\"][\"projection_channels\"]\n",
    "        n_layers = config[\"dfc\"][\"fourier_part\"][\"n_layers\"]\n",
    "        decomposition = config[\"dfc\"][\"fourier_part\"][\"factorization\"]\n",
    "        implementation = config[\"dfc\"][\"fourier_part\"][\"implementation\"]\n",
    "        rank = config[\"dfc\"][\"fourier_part\"][\"rank\"]\n",
    "        mem_checkpoint = config[\"dfc\"][\"fourier_part\"][\"mem_checkpoint\"]\n",
    "        separable_fourier_layers = config[\"dfc\"][\"fourier_part\"][\"separable_fourier_layers\"]\n",
    "        batch_norm = config[\"dfc\"][\"fourier_part\"][\"batch_norm\"]\n",
    "        fno_block_precision = config[\"dfc\"][\"fourier_part\"][\"fourier_block_precision\"]\n",
    "\n",
    "\n",
    "        kernel_size = config[\"dfc\"][\"dilated_cnn_part\"][\"kernel_size\"]\n",
    "        padding = config[\"dfc\"][\"dilated_cnn_part\"][\"padding\"]\n",
    "        dilations = config[\"dfc\"][\"dilated_cnn_part\"][\"dilations\"]\n",
    "        dfc = f_c_network(in_channels=in_channels, width=hidden_channels, n_modes=(n_modes,n_modes), fourier_interpolate=fourier_interpolation, bias = bias,\n",
    "        spectral_dilation_fac=dilate_fourier_kernel_fac, decomposition=decomposition, rank = rank, implementation=implementation, \n",
    "                    separable_fourier_layers=separable_fourier_layers, mem_checkpoint=mem_checkpoint, skip = skip, batch_norm=batch_norm,\n",
    "                    fno_block_precision=fno_block_precision, \n",
    "                    lifting_channels=lifting_channels, \n",
    "                    projection_channels=projection_channels, kernel_size=kernel_size, padding=padding,\n",
    "                    dilations=dilations, num_layers=n_layers,).to(device)\n",
    "\n",
    "\n",
    "        load_checkpoint(torch.load(config[\"dfc\"][\"data\"][\"LOAD_CHECKPOINT_DIR\"]), dfc, None)\n",
    "        \n",
    "    if config[\"test\"][\"unet\"]:\n",
    "        in_channels = config[\"unet\"][\"build\"][\"in_channels\"]\n",
    "        in_size = config[\"unet\"][\"build\"][\"in_size\"]\n",
    "        out_channels = config[\"unet\"][\"build\"][\"out_channels\"]\n",
    "        latent_lift_proj_dim = config[\"unet\"][\"build\"][\"latent_lift_proj_dim\"]\n",
    "        n_layers = config[\"unet\"][\"build\"][\"n_layers\"]\n",
    "        n_res = config[\"unet\"][\"build\"][\"n_res\"]\n",
    "        activations = config[\"unet\"][\"build\"]['activations']\n",
    "\n",
    "        unet = CNO(in_dim = in_channels, in_size = in_size, N_layers = n_layers, out_dim = out_channels,\n",
    "     activation = activations, N_res=n_res, latent_lift_proj_dim=latent_lift_proj_dim).to(device = device)\n",
    "        \n",
    "\n",
    "        # unet = uperconvnext(in_channels = in_channels, out_channels = out_channels).to(device = device)\n",
    "       \n",
    "        # unet = smp.DeepLabV3(encoder_name = 'resnet101' ,in_channels = in_channels, classes = out_channels, activation = None).to(device = device)\n",
    "\n",
    "        \n",
    "        load_checkpoint(torch.load(config[\"unet\"][\"data\"][\"LOAD_CHECKPOINT_DIR\"]), unet, None)\n",
    "        \n",
    "    return dfc, unet\n",
    "    \n",
    "def _infer(inp, dfc, unet, config, device, dist_from_corner, crop_size,):\n",
    "    predictions = []\n",
    "\n",
    "    # local crops if different fov-trained unet is used\n",
    "    # dist_from_corner = 128\n",
    "    # crop_size = 384\n",
    "    slice_holo = (slice(None), slice(None), slice(dist_from_corner, crop_size-dist_from_corner), slice(dist_from_corner, crop_size-dist_from_corner))\n",
    "    std_scale_factor_128to384 = 0.6904758593396808\n",
    "    std_diffccde_level_factor = 9200/12000\n",
    "    # put the dfc in eval mode \n",
    "    if unet is not None and dfc is None:\n",
    "        unet.eval()\n",
    "        unet_mean = config[\"unet\"][\"evaluation\"][\"mean\"]\n",
    "        unet_std = config[\"unet\"][\"evaluation\"][\"std\"]\n",
    "        # storing predictions for analysing later \n",
    "        with torch.no_grad():\n",
    "            for i in trange(inp.shape[0]):\n",
    "    \n",
    "                img = ((inp[i].unsqueeze(0)-unet_mean[0])/unet_std[0]).to(device = device)\n",
    "                \n",
    "                prediction = torch.sigmoid(unet(img))[slice_holo] # adjust accordingly \n",
    "                predictions.append(prediction.cpu())\n",
    "    \n",
    "\n",
    "    if unet is not None and dfc is not None:\n",
    "        unet.eval()\n",
    "        dfc.eval()\n",
    "\n",
    "        unet_mean = config[\"unet\"][\"evaluation\"][\"mean\"]\n",
    "        unet_std = config[\"unet\"][\"evaluation\"][\"std\"]\n",
    "        dfc_mean = config[\"dfc\"][\"evaluation\"][\"mean\"]\n",
    "        dfc_std = config[\"dfc\"][\"evaluation\"][\"std\"]\n",
    "\n",
    "        \n",
    "        store_wholo = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in trange(inp.shape[0]):    \n",
    "                                    \n",
    "                img = ((inp[i].unsqueeze(0)-dfc_mean[0])/dfc_std[0]).to(device = device)\n",
    "                # img = ((inp[i].unsqueeze(0)-torch.mean(inp[i]))/torch.std(inp[i])).to(device = device)\n",
    "                \n",
    "                grid = get_grid(img.shape, device = device)\n",
    "                img = torch.concat((img, grid), dim = 1)\n",
    "\n",
    "                prediction_holo = dfc(img) # have to place before continue statment otherwise mismatch with gt\n",
    "                store_wholo.append(prediction_holo[0].cpu())\n",
    "\n",
    "                img = torch.clip((inp[i].unsqueeze(0).to(device = device) - 128)*std_diffccde_level_factor+128, 0, 255)\n",
    "                prediction_holo = torch.concat(((img - unet_mean[0])/(unet_std[0]/std_scale_factor_128to384), (prediction_holo - unet_mean[1])/unet_std[1]), dim = 1)\n",
    "                \n",
    "                prediction = torch.sigmoid(unet(prediction_holo))[slice_holo]\n",
    "                # print(prediction.max(), prediction.min())\n",
    "                \n",
    "                # plt.imshow(prediction[0,0].cpu().detach().numpy())\n",
    "                predictions.append(prediction.cpu())\n",
    "            \n",
    "\n",
    "    store_xy2, store_z2, store_r2 = [], [], [],\n",
    "    print(\"Separating xy, z and size channels in different lists for further analysis...\")\n",
    "    for pred in predictions:\n",
    "        store_xy2.append(pred[:,0])\n",
    "        store_z2.append(pred[:,1]*200)\n",
    "        store_r2.append(pred[:,2]*100)\n",
    "    if dfc is not None:\n",
    "        return store_wholo, store_xy2, store_z2, store_r2\n",
    "    else:\n",
    "        return  store_xy2, store_z2, store_r2\n",
    "\n",
    "\n",
    "def _get_throughput(dfc, unet, optimal_batch_size, inp_shape, device):\n",
    "        \n",
    "    repetitions=100\n",
    "    total_time = 0\n",
    "    timings = np.zeros((repetitions))\n",
    "\n",
    "    if unet is not None and dfc is None:\n",
    "        unet.eval()\n",
    "        dummy_input = torch.randn(optimal_batch_size, 1, *inp_shape, dtype=torch.float).to(device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            with torch.no_grad():\n",
    "                for i in trange(repetitions):\n",
    "                    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "                    starter.record()\n",
    "                    _ = torch.sigmoid(unet(dummy_input))  \n",
    "                    ender.record()\n",
    "                    torch.cuda.synchronize()\n",
    "                    curr_time = starter.elapsed_time(ender)/1000\n",
    "                    total_time += curr_time\n",
    "                    timings[i] = curr_time\n",
    "\n",
    "\n",
    "    if unet is not None and dfc is not None:\n",
    "        unet.eval()\n",
    "        dfc.eval()\n",
    "\n",
    "        unet_mean = config[\"unet\"][\"evaluation\"][\"mean\"]\n",
    "        unet_std = config[\"unet\"][\"evaluation\"][\"std\"]\n",
    "        dfc_mean = config[\"dfc\"][\"evaluation\"][\"mean\"]\n",
    "        dfc_std = config[\"dfc\"][\"evaluation\"][\"std\"]\n",
    "\n",
    "        dummy_input = torch.randn(optimal_batch_size, 1, *inp_shape, dtype=torch.float).to(device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            with torch.no_grad():\n",
    "                for i in trange(repetitions):    \n",
    "                    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "                    starter.record()\n",
    "                    prediction_holo = dfc(torch.concat((dummy_input, get_grid(dummy_input.shape, device = device)), dim = 1)) # have to place before continue statment otherwise mismatch with gt\n",
    "                    prediction_holo = torch.concat(((dummy_input*dfc_std[0]+dfc_mean[0] - unet_mean[0])/unet_std[0],\n",
    "                                                    (prediction_holo - unet_mean[1])/unet_std[1]), dim = 1)\n",
    "                    _ = torch.sigmoid(unet(prediction_holo))\n",
    "                    ender.record()\n",
    "                    torch.cuda.synchronize()\n",
    "                    curr_time = starter.elapsed_time(ender)/1000\n",
    "                    total_time += curr_time\n",
    "                    timings[i] = curr_time\n",
    "\n",
    "    # total_time = np.sum(timings)\n",
    "    # total_time_std = np.std(timings)\n",
    "    Throughput = (repetitions*optimal_batch_size)/total_time\n",
    "    mean_time_per_batch = np.mean(timings)\n",
    "    std_timer_per_batch = np.std(timings)\n",
    "    # print(\"Final Throughput:\",Throughput)\n",
    "    return Throughput, [mean_time_per_batch,std_timer_per_batch]\n",
    "\n",
    "def _get_inference_times(dfc, unet, inp_shape, device):\n",
    "    \n",
    "    if unet is not None and dfc is None:\n",
    "        unet.eval()\n",
    "        dummy_input = torch.randn(1, 1, *inp_shape, dtype=torch.float).to(device)\n",
    "\n",
    "        starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "        repetitions = 300\n",
    "        timings=np.zeros((repetitions,1))\n",
    "        #GPU-WARM-UP\n",
    "        for _ in range(10):\n",
    "            _ = torch.sigmoid(unet(prediction_holo))\n",
    "        with torch.cuda.amp.autocast():\n",
    "            with torch.no_grad():\n",
    "                for i in trange(repetitions):\n",
    "                    starter.record()\n",
    "                    _ = torch.sigmoid(unet(dummy_input))  \n",
    "                    ender.record()\n",
    "                    torch.cuda.synchronize()\n",
    "                    curr_time = starter.elapsed_time(ender)/1000\n",
    "                    timings[i] = curr_time\n",
    "\n",
    "\n",
    "    if unet is not None and dfc is not None:\n",
    "        unet.eval()\n",
    "        dfc.eval()\n",
    "\n",
    "        unet_mean = config[\"unet\"][\"evaluation\"][\"mean\"]\n",
    "        unet_std = config[\"unet\"][\"evaluation\"][\"std\"]\n",
    "        dfc_mean = config[\"dfc\"][\"evaluation\"][\"mean\"]\n",
    "        dfc_std = config[\"dfc\"][\"evaluation\"][\"std\"]\n",
    "\n",
    "        dummy_input = torch.randn(1, 1, *inp_shape, dtype=torch.float).to(device)\n",
    "        \n",
    "        starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "        repetitions = 300\n",
    "        timings=np.zeros((repetitions,1))\n",
    "        \n",
    "        #warm_up\n",
    "        for _ in range(10):\n",
    "            prediction_holo = dfc(torch.concat((dummy_input, get_grid(dummy_input.shape, device = device)), dim = 1)) # have to place before continue statment otherwise mismatch with gt\n",
    "            prediction_holo = torch.concat(((dummy_input*dfc_std[0]+dfc_mean[0] - unet_mean[0])/unet_std[0],\n",
    "                                                 (prediction_holo - unet_mean[1])/unet_std[1]), dim = 1)\n",
    "            _ = torch.sigmoid(unet(prediction_holo))\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            with torch.no_grad():\n",
    "                for i in trange(repetitions):    \n",
    "                    starter.record()\n",
    "                    prediction_holo = dfc(torch.concat((dummy_input, get_grid(dummy_input.shape, device = device)), dim = 1)) # have to place before continue statment otherwise mismatch with gt\n",
    "                    prediction_holo = torch.concat(((dummy_input*dfc_std[0]+dfc_mean[0] - unet_mean[0])/unet_std[0],\n",
    "                                                    (prediction_holo - unet_mean[1])/unet_std[1]), dim = 1)\n",
    "                    _ = torch.sigmoid(unet(prediction_holo))\n",
    "                    ender.record()\n",
    "                    torch.cuda.synchronize()\n",
    "                    curr_time = starter.elapsed_time(ender)/1000\n",
    "                    timings[i] = curr_time\n",
    "\n",
    "\n",
    "    # print(f\"Inference_time: {np.mean(timings)} $\\pm$ {np.std(timings)}\",)\n",
    "    return f\"{np.mean(timings):.4f} $\\pm$ {np.std(timings):.4f}\"\n",
    "\n",
    "def _get_memory_stats(dfc, unet, inp_shape, device):\n",
    "    if unet is not None and dfc is None:\n",
    "        unet.eval()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            dummy_input = torch.randn(1, 1, *inp_shape, dtype=torch.float).to(device)\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            preditiction = torch.sigmoid(unet(prediction_holo))\n",
    "            unet_act_mem = torch.cuda.max_memory_allocated() / 1024**3\n",
    "            # print(f\"Memory due to activations: {torch.cuda.max_memory_allocated() / 1024**3} GB\")        \n",
    "        return [(count_params(unet)*4/(1024**3), unet_act_mem)]\n",
    "        \n",
    "    if unet is not None and dfc is not None:\n",
    "        unet.eval()\n",
    "        dfc.eval()\n",
    "\n",
    "        unet_mean = config[\"unet\"][\"evaluation\"][\"mean\"]\n",
    "        unet_std = config[\"unet\"][\"evaluation\"][\"std\"]\n",
    "        dfc_mean = config[\"dfc\"][\"evaluation\"][\"mean\"]\n",
    "        dfc_std = config[\"dfc\"][\"evaluation\"][\"std\"]\n",
    "        with torch.cuda.amp.autocast():\n",
    "            dummy_input = torch.randn(1, 1, *inp_shape, dtype=torch.float).to(device)\n",
    "            dummy_input_with_xychannels = torch.concat((dummy_input, get_grid(dummy_input.shape, device = device)), dim = 1)\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            prediction_holo = dfc(dummy_input_with_xychannels) # have to place before continue statment otherwise mismatch with gt\n",
    "            dfc_act_mem = torch.cuda.max_memory_allocated() / 1024**3\n",
    "            prediction_holo = torch.concat(((dummy_input*dfc_std[0]+dfc_mean[0] - unet_mean[0])/unet_std[0],\n",
    "                                                    (prediction_holo - unet_mean[1])/unet_std[1]), dim = 1)\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            preditiction = torch.sigmoid(unet(prediction_holo))\n",
    "            unet_act_mem = torch.cuda.max_memory_allocated() / 1024**3\n",
    "        \n",
    "        # print(f\"Memory occupied by the model: {(count_params(unet)+count_params(dfc))*4/(1024**3)} GB\")\n",
    "\n",
    "        return [(count_params(unet)*4/(1024**3), unet_act_mem-count_params(unet)*4/(1024**3)), \n",
    "                 (count_params(dfc)*4/(1024**3), dfc_act_mem-count_params(dfc)*4/(1024**3))]\n",
    "\n",
    "\n",
    "def get_forward_backward_memory_max_batch_size(model, shape):\n",
    "    x = torch.randn(shape).cuda()\n",
    "    if isinstance(model, f_c_network):\n",
    "        x = torch.concat((x, get_grid(x.shape, device=x.device)), dim = 1)\n",
    "    # dummy inits \n",
    "    loss = nn.MSELoss()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "    # with torch.no_grad():\n",
    "    #     print(model(x).cpu().detach().numpy().shape)\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    init_mem = torch.cuda.max_memory_allocated()\n",
    "    with torch.cuda.amp.autocast(enabled=True):\n",
    "        # print(x.dtype)\n",
    "        y = model(x)\n",
    "        torch.cuda.synchronize()\n",
    "        forw_mem = torch.cuda.max_memory_allocated()\n",
    "        # print(y.dtype)\n",
    "        l = loss(x[:,0,:,:].unsqueeze(1), y)   \n",
    "        \n",
    "    scaler.scale(l).backward() # ?\n",
    "            # optimizer.step()\n",
    "    scaler.step(optimizer) # ?\n",
    "    scaler.update()        # ?\n",
    "    torch.cuda.synchronize()\n",
    "    back_mem = torch.cuda.max_memory_allocated()\n",
    "    \n",
    "\n",
    "\n",
    "    if init_mem is None:    \n",
    "        init_mem = 0\n",
    "    print(f\"Batch size:{x.shape[0]}\", (\"Forward:%.2f\"%((forw_mem) / 1024**3), \"Backward:%.2f\"%((back_mem) / 1024**3), \"Init:%.2f\"%(init_mem/1024**3)), \"%.2f\" % (count_params(model)* 32/8/1024**3))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return (forw_mem) / 1024**3, (back_mem) / 1024**3, (init_mem/1024**3)\n",
    "\n",
    "\n",
    "def _get_fig_axes(nrows, ncols, width, fraction, sharex = 'col', sharey = 'row', layout = 'constrained'):\n",
    "    fig, axes = plt.subplots(nrows,ncols,figsize = set_size(width=width, fraction = fraction, subplots = (nrows,ncols)), sharex=sharex, sharey = sharey,layout = layout)\n",
    "    for ax in axes.flat:\n",
    "        ax.set_xlabel('X Label')\n",
    "        ax.set_ylabel('Y Label')\n",
    "\n",
    "        ax.xaxis.set_tick_params(width=0.5)\n",
    "        ax.yaxis.set_tick_params(width=0.5)\n",
    "\n",
    "        ax.spines['bottom'].set_linewidth(0.5) # Line width for the bottom axis\n",
    "        ax.spines['left'].set_linewidth(0.5)\n",
    "\n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "def _plot_(P, R, ez, ed, z_det, d_det, d_total, z_total):\n",
    "    color_fc = colors[0]\n",
    "    Z = [50, 75, 99, 167, 192,]\n",
    "    d_bins = [5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 13.5, 16.5, 23.5, 56.5, 83.5]\n",
    "    center_points_for_d_bins = [int((d_bins[i]+d_bins[i+1])/2) for i in range(len(d_bins)-1)]\n",
    "\n",
    "\n",
    "    fig, axes = _get_fig_axes(3, 5, 'iccv', 1,)\n",
    "    \n",
    "    for ax in axes.flat:\n",
    "        ax.set_xlabel(r'Diameter$_{GT}$ [Âµm]')\n",
    "\n",
    "\n",
    "    sns.despine()\n",
    "\n",
    "    showfliers = False\n",
    "    showcaps = True\n",
    "    whis = True\n",
    "\n",
    "    errors_d_d = {}\n",
    "    errors_z_d = {}\n",
    "        \n",
    "    for j,z in enumerate(Z):\n",
    "        z_mask = z_det == z\n",
    "        get_bin_idx = np.digitize(d_det[z_mask], bins = d_bins)\n",
    "       \n",
    "        if z not in errors_d_d:\n",
    "            errors_d_d[z] = {}\n",
    "            errors_z_d[z] = {}\n",
    "        for i, size in enumerate(center_points_for_d_bins):\n",
    "            if size not in errors_d_d:\n",
    "                errors_d_d[z][size] = []\n",
    "                errors_z_d[z][size] = []\n",
    "                \n",
    "            \n",
    "            errors_d_d[z][size].append([ed[z_mask][get_bin_idx == i+1]])\n",
    "            errors_z_d[z][size].append([ez[z_mask][get_bin_idx == i+1]])\n",
    "            \n",
    "            \n",
    "        \n",
    "        fc_ed_d = [np.array(errors_d_d[z][key][0][0]) for key in errors_d_d[z]]\n",
    "        fc_ez_d = [np.array(errors_z_d[z][key][0][0]) for key in errors_z_d[z]]\n",
    "        fc_d_det = d_det[z_mask]\n",
    "        # return errors_d_d, d_det_z\n",
    "        # print(fc_d_det)\n",
    "        tmp_error_xticklabels = range(len(fc_ed_d))\n",
    "\n",
    "\n",
    "        for i in range(axes.shape[0]):\n",
    "\n",
    "            ax1, ax2, ax3 = [*axes[:,j]]\n",
    "\n",
    "            hist, bin_centers = np.histogram(d_total[z_total == z], d_bins)\n",
    "            tmp_range = range(1,len(hist)+1)\n",
    "            ax1.bar(tmp_range, hist, color = 'white', edgecolor = 'black', label = 'GT', linewidth = 0.8)\n",
    "            hist, bin_centers = np.histogram(fc_d_det, d_bins)\n",
    "            tmp_range = range(1,len(hist)+1)\n",
    "            ax1.bar(tmp_range, hist, alpha = 0.3, label = 'NOA', color = color_fc)\n",
    "            ax1.set_yscale(\"linear\")\n",
    "\n",
    "\n",
    "\n",
    "            ax1.set_xticks([i for i,j in enumerate(hist)])\n",
    "            xticklabels = [f\"{d_bins[i]-0.5}-{d_bins[i+1]-0.5}\" for i in range(len(d_bins)-1)]\n",
    "            ax1.set_xticklabels(xticklabels, rotation = 45)\n",
    "            ax1.set_ylabel(r\"$\\#$particles\")\n",
    "\n",
    "\n",
    "            fc_bplot_ed_d = ax2.boxplot(fc_ed_d, label=tmp_error_xticklabels, patch_artist=True, showfliers=showfliers, showcaps = showcaps, whis = whis)\n",
    "            for patch in fc_bplot_ed_d['boxes']:\n",
    "                patch.set_edgecolor(color_fc)\n",
    "                patch.set_facecolor(\"none\")\n",
    "\n",
    "            for patch in fc_bplot_ed_d['fliers']:\n",
    "                patch.set(markeredgecolor=color_fc, markersize = 2)\n",
    "\n",
    "\n",
    "            for patch in fc_bplot_ed_d['whiskers']:\n",
    "                patch.set_color(color_fc)\n",
    "\n",
    "            for patch in fc_bplot_ed_d['medians']:\n",
    "                patch.set_color(color_fc)\n",
    "\n",
    "            for cap in fc_bplot_ed_d['caps']:\n",
    "                cap.set_color(color_fc)\n",
    "\n",
    "        \n",
    "\n",
    "            ax2.set_xticks([i+1 for i,j in enumerate(fc_ed_d)])\n",
    "            xticklabels = [f\"{d_bins[i]}-{d_bins[i+1]}\" for i in range(len(d_bins)-1)]\n",
    "            ax2.set_xticklabels(xticklabels, rotation = 45,)\n",
    "            ax2.set_ylabel(r\"err$_{diam}$[Âµm]\")\n",
    "            # ax2.set_yscale('log')\n",
    "\n",
    "\n",
    "            # ax2.get_yaxis().set_major_formatter(plticker.ScalarFormatter())\n",
    "            ax2.yaxis.set_minor_locator(plticker.MultipleLocator(5))\n",
    "\n",
    "            fc_bplot_ez_d = ax3.boxplot(fc_ez_d, label=tmp_error_xticklabels, patch_artist=True, showfliers=showfliers, showcaps = showcaps, whis = whis)\n",
    "            for patch in fc_bplot_ez_d['boxes']:\n",
    "                patch.set_edgecolor(color_fc)\n",
    "                patch.set_facecolor(\"none\")\n",
    "\n",
    "            for patch in fc_bplot_ez_d['fliers']:\n",
    "                patch.set(markeredgecolor=color_fc, markersize = 2)\n",
    "\n",
    "            for patch in fc_bplot_ez_d['whiskers']:\n",
    "                patch.set_color(color_fc)\n",
    "\n",
    "            for patch in fc_bplot_ez_d['medians']:\n",
    "                patch.set_color(color_fc)\n",
    "\n",
    "            for cap in fc_bplot_ez_d['caps']:\n",
    "                cap.set_color(color_fc)\n",
    "\n",
    "\n",
    "            ax3.set_xticks([i+1 for i,j in enumerate(fc_ez_d)])\n",
    "            xticklabels = [f\"{int(d_bins[i]-0.5)}-{int(d_bins[i+1]-0.5)}\" for i in range(len(d_bins)-1)]\n",
    "            ax3.set_xticklabels(xticklabels, rotation = 60,)\n",
    "            ax3.set_xlabel(r\"diameter$_{GT}$[Âµm]\")\n",
    "            ax3.set_ylabel(r\"err$_z$[mm]\")\n",
    "            # ax3.set_yscale('log')\n",
    "\n",
    "\n",
    "            # ax3.get_yaxis().set_major_formatter(plticker.ScalarFormatter())\n",
    "            # ax3.yaxis.set_major_locator(plticker.MultipleLocator(0.5))\n",
    "            ax3.yaxis.set_minor_locator(plticker.MultipleLocator(5))\n",
    "\n",
    "    for i in range(axes.shape[0]):\n",
    "        for j in range(axes.shape[1]):\n",
    "            if i!=axes.shape[0]-1:\n",
    "                axes[i,j].set_xlabel(\"\")\n",
    "                axes[i,j].xaxis.set_visible(False)\n",
    "                axes[i,j].spines['bottom'].set_visible(False)\n",
    "            if j!=0:\n",
    "                axes[i,j].set_ylabel(\"\")\n",
    "                axes[i,j].yaxis.set_visible(False)\n",
    "                axes[i,j].spines['left'].set_visible(False)\n",
    "            if i ==0:\n",
    "                axes[i,j].set_yscale('linear')\n",
    "\n",
    "    return errors_d_d, errors_z_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "img_files = glob.glob(\"/CloudTarget_holograms/\") # these are master filtered holograms \n",
    "\n",
    "\n",
    "######### DO NOT CHANGE ###########\n",
    "m_files = [\"/CloudTarget_labels/\"]\n",
    "###################################\n",
    "\n",
    "\n",
    "\n",
    "num_files = len(img_files)\n",
    "assert num_files == len(m_files), print(\"Image and Mask lists are not of equal length!\") \n",
    "print(\"Number of files:\", num_files)\n",
    "\n",
    "\n",
    "ds_factor = config[\"dfc\"][\"evaluation\"][\"ds_factor\"] # if you downsample for inference \n",
    "\n",
    "W = config[\"dfc\"][\"evaluation\"][\"HOLO_SIZE\"] # recorded holograms are square and of this dimension\n",
    "H = config[\"dfc\"][\"evaluation\"][\"HOLO_SIZE\"]\n",
    "crop_size = config[\"dfc\"][\"evaluation\"][\"crop_size\"] # adjust accordingly (this number should be NOT downsampled dimension)\n",
    "step_size = config['dfc'][\"evaluation\"][\"step_size\"]\n",
    "\n",
    "# applying the downsampling effect below\n",
    "W = W//ds_factor \n",
    "H = H//ds_factor\n",
    "crop_size = crop_size//ds_factor\n",
    "# crop_size = 256\n",
    "step_size = step_size//ds_factor\n",
    "mask_crop_size = crop_size # (xy,z,d) mask; adjust the size accordingly, this is temporary mask_crop_size here though \n",
    "# mask_crop_size = 128\n",
    "assert W-crop_size >= 0, print(\"Asked crop size is bigger than the image itself\")\n",
    "\n",
    "# crop_size and original hologram size (H,W) might not be exactly divisible, so we crop some edges. Adjust accordingly. \n",
    "dist_to_cut_from_edge = int(config[\"dfc\"][\"evaluation\"][\"dist_to_cut_from_edge\"]//ds_factor)\n",
    "holo_size = W - dist_to_cut_from_edge*2 # after downsampling \n",
    "print(f\"Hologram size after cutting given edge distance to crop:\", holo_size*ds_factor)\n",
    "anti_step_size = crop_size - step_size # 0 if no overlapping\n",
    "num_crops_per_holo = ((W-crop_size)//step_size+1)**2 # formula: crop_size*n - (crop_size-step_size)*(n-1) = holo_size, n is the number of crops you will get of size crop_size = num_holos\n",
    "dist_to_cut_from_each_edge = int((W - (crop_size*np.sqrt(num_crops_per_holo) - (anti_step_size*(np.sqrt(num_crops_per_holo)-1))))//2)\n",
    "# dist_to_cut_from_each_edge = 0\n",
    "print(f\"Distance being cut from each corner in the downsampled hologram ({W*ds_factor}/{ds_factor}): {dist_to_cut_from_each_edge*ds_factor}\")\n",
    "\n",
    "total_edge_to_crop = int(dist_to_cut_from_edge)\n",
    "holo_size = W - total_edge_to_crop*2 # after cropping\n",
    "crops_per_hologram = num_crops_per_holo\n",
    "print(f\"Number of crops per {H}x{H} downsampled hologram: {crops_per_hologram}\")\n",
    "\n",
    "gkern_size = config[\"unet\"][\"evaluation\"][\"gkern_size\"] # size of the gaussian blob, controls the strictness of the hitbox\n",
    "\n",
    "# Evaluate for preicison and recall\n",
    "cutoff_range = config[\"unet\"][\"evaluation\"][\"cutoff_range\"] # will check 100 values between 0 and 1\n",
    "min_distance = config[\"unet\"][\"evaluation\"][\"min_distance\"]  # min distance b/w consecutive peaks in the prediction, can controle this\n",
    "\n",
    "error_calc = config[\"unet\"][\"evaluation\"][\"error_calc\"]\n",
    "max_r = config[\"unet\"][\"evaluation\"][\"max_r\"] # max particle size in the gt, Âµm\n",
    "min_r = config[\"unet\"][\"evaluation\"][\"min_r\"] # min particle size in the gt \n",
    "min_z = config[\"unet\"][\"evaluation\"][\"min_z\"] # mm\n",
    "max_z = config[\"unet\"][\"evaluation\"][\"max_z\"]\n",
    "ez_allowed = config[\"unet\"][\"evaluation\"][\"ez_allowed\"] # if error in z greater than 10mm, count the prediction as fasle postive\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Getting i/o data...\")\n",
    "    inp = make_img_crops(img_files, crops_per_hologram, crop_size, step_size, W, total_edge_to_crop, ds_factor)\n",
    "    tgt = make_msk_crops(m_files, crops_per_hologram, crop_size, step_size, W, total_edge_to_crop, ds_factor, gkern_size, anti_step_size//2)\n",
    "    print(inp.shape)\n",
    "    print(f\"\\nTest data input shape is {inp.shape} and target shape is {tgt.shape}\")    \n",
    "    print(\"\\nGetting models...\")\n",
    "    dfc, unet = _get_dfcs(config, )\n",
    "    print(f\"\\n Making predictions...\")    \n",
    "    if config[\"test\"][\"dfc\"]:\n",
    "        store_wholo, store_xy2, store_z2, store_r2 = _infer(inp, dfc, unet, config, device=config[\"test\"][\"device\"], dist_from_corner=64, crop_size=crop_size)\n",
    "        print(inp.shape)\n",
    "    else:\n",
    "        store_xy2, store_z2, store_r2 = _infer(inp, dfc, unet, config, device=config[\"test\"][\"device\"], dist_from_corner=dist_to_cut_from_each_edge, crop_size=crop_size)\n",
    "    \n",
    "    print(\"\\nAnalyzing results...\")\n",
    "    if error_calc:\n",
    "        prediction_dict  = _eval_prec_rec_f1_(tgt, store_xy2, store_z2, store_r2, gkern_size, num_files, num_crops_per_holo,\n",
    "                                                                                   cutoff_range, min_distance, max_r, min_r, max_z, min_z, ez_allowed, error_calc)\n",
    "    else:\n",
    "        P, R, f1_score, P_star, R_star, best_f1  = _eval_prec_rec_f1_(tgt, store_xy2, store_z2, store_r2, gkern_size, num_files, num_crops_per_holo,\n",
    "                                                                                cutoff_range, min_distance, max_r, min_r, max_z, min_z, ez_allowed, error_calc)\n",
    "\n",
    "    optimal_batch_size = config[\"dfc\"][\"evaluation\"][\"optimal_batch_size\"]\n",
    "\n",
    "    for batch_size in optimal_batch_size:\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()\n",
    "        try:\n",
    "            throughput, timings = _get_throughput(dfc, unet, batch_size, inp.shape[2:], device=config[\"test\"][\"device\"])\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Exceeding GPU memory for batch size {batch_size}\")\n",
    "            with torch.no_grad():\n",
    "                torch.cuda.empty_cache()\n",
    "    opt_batch_size = batch_size\n",
    "\n",
    "\n",
    "    train_max_batch_size = [32,28,24,20,16,14,12,10,8,6,4,2,1]\n",
    "    for batch_size in train_max_batch_size:\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()\n",
    "        try:\n",
    "            if dfc is not None:\n",
    "                fow_mem, back_mem,_ = get_forward_backward_memory_max_batch_size(dfc, (batch_size, *inp.shape[1:]))\n",
    "            else: \n",
    "                fow_mem, back_mem,_ = get_forward_backward_memory_max_batch_size(unet, (batch_size, *inp.shape[1:]))\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Exceeding GPU memory for batch size {batch_size}\", e)\n",
    "            with torch.no_grad():\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "\n",
    "\n",
    "    crop_sz = config[\"dfc\"][\"training\"][\"IMG_SIZE\"]\n",
    "    kern_sz = config[\"dfc\"][\"fourier_part\"][\"n_modes\"]\n",
    "    rank = config[\"dfc\"][\"fourier_part\"][\"rank\"]\n",
    "\n",
    "    P_star = prediction_dict[\"precision_at_best_f1\"]\n",
    "    R_star = prediction_dict[\"recall_at_best_f1\"]\n",
    "    best_f1 = prediction_dict[\"best_F1\"]\n",
    "    output_str = f\"{crop_sz} & {rank}  & {P_star:.3f} & {R_star:.3f} & {best_f1:.3f} & {count_params(unet)*32/8/1024**3:.2f} & {fow_mem:.2f} & {timings[0]/(opt_batch_size/crops_per_hologram):.4f}$\\pm${timings[1]/(opt_batch_size/crops_per_hologram):.4f}\"\n",
    "    print(output_str)\n",
    "\n",
    "\n",
    "    # # save the above\n",
    "    print(\"saving...\")\n",
    "    with open(config[\"unet\"][\"data\"][\"SAVE_FOLDER\"]+\"flashÂµ_predictions.pkl\", mode = 'wb+') as f:\n",
    "        pickle.dump(prediction_dict, f)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holography",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
